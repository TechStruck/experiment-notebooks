{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import Session\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import zlib\n",
    "\n",
    "# Directly taken and modified from Rapptz/RoboDanny\n",
    "# https://github.com/Rapptz/RoboDanny/blob/715a5cf8545b94d61823f62db484be4fac1c95b1/cogs/api.py\n",
    "# This code is under the Mozilla Public License 2.0\n",
    "\n",
    "\n",
    "class SphinxObjectFileReader:\n",
    "    # Inspired by Sphinx's InventoryFileReader\n",
    "    BUFSIZE = 16 * 1024\n",
    "\n",
    "    def __init__(self, buffer):\n",
    "        self.stream = io.BytesIO(buffer)\n",
    "\n",
    "    def readline(self):\n",
    "        return self.stream.readline().decode(\"utf-8\")\n",
    "\n",
    "    def skipline(self):\n",
    "        self.stream.readline()\n",
    "\n",
    "    def read_compressed_chunks(self):\n",
    "        decompressor = zlib.decompressobj()\n",
    "        while True:\n",
    "            chunk = self.stream.read(self.BUFSIZE)\n",
    "            if len(chunk) == 0:\n",
    "                break\n",
    "            yield decompressor.decompress(chunk)\n",
    "        yield decompressor.flush()\n",
    "\n",
    "    def read_compressed_lines(self):\n",
    "        buf = b\"\"\n",
    "        for chunk in self.read_compressed_chunks():\n",
    "            buf += chunk\n",
    "            pos = buf.find(b\"\\n\")\n",
    "            while pos != -1:\n",
    "                yield buf[:pos].decode(\"utf-8\")\n",
    "                buf = buf[pos + 1 :]\n",
    "                pos = buf.find(b\"\\n\")\n",
    "\n",
    "    def parse_object_inv(self, url):\n",
    "        # key: URL\n",
    "        # n.b.: key doesn't have `discord` or `discord.ext.commands` namespaces\n",
    "        result = {}\n",
    "\n",
    "        # first line is version info\n",
    "        inv_version = self.readline().rstrip()\n",
    "\n",
    "        if inv_version != \"# Sphinx inventory version 2\":\n",
    "            raise RuntimeError(\"Invalid objects.inv file version.\")\n",
    "\n",
    "        # next line is \"# Project: <name>\"\n",
    "        # then after that is \"# Version: <version>\"\n",
    "        projname = self.readline().rstrip()[11:]\n",
    "        version = self.readline().rstrip()[11:]\n",
    "\n",
    "        # next line says if it's a zlib header\n",
    "        line = self.readline()\n",
    "        if \"zlib\" not in line:\n",
    "            raise RuntimeError(\"Invalid objects.inv file, not z-lib compatible.\")\n",
    "\n",
    "        # This code mostly comes from the Sphinx repository.\n",
    "        entry_regex = re.compile(r\"(?x)(.+?)\\s+(\\S*:\\S*)\\s+(-?\\d+)\\s+(\\S+)\\s+(.*)\")\n",
    "        for line in self.read_compressed_lines():\n",
    "            match = entry_regex.match(line.rstrip())\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            name, directive, prio, location, dispname = match.groups()\n",
    "            domain, _, subdirective = directive.partition(\":\")\n",
    "            if directive == \"py:module\" and name in result:\n",
    "                # From the Sphinx Repository:\n",
    "                # due to a bug in 1.1 and below,\n",
    "                # two inventory entries are created\n",
    "                # for Python modules, and the first\n",
    "                # one is correct\n",
    "                continue\n",
    "\n",
    "            # Most documentation pages have a label\n",
    "            if directive == \"std:doc\":\n",
    "                subdirective = \"label\"\n",
    "\n",
    "            if location.endswith(\"$\"):\n",
    "                location = location[:-1] + name\n",
    "\n",
    "            key = name if dispname == \"-\" else dispname\n",
    "            prefix = f\"{subdirective}:\" if domain == \"std\" else \"\"\n",
    "\n",
    "            result[f\"{prefix}{key}\"] = os.path.join(url, location)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://docs.python.org/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = session.get(base_url + \"/objects.inv\")\n",
    "sph = SphinxObjectFileReader(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sph.parse_object_inv(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [key for key in list(data.keys()) if is_valid(key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(key: str):\n",
    "    key = key.split(\".\")[-1]\n",
    "    return (\n",
    "        key\n",
    "        and not key.replace(\"_\", \"\").isupper()\n",
    "        and not key.startswith(\"Py\")\n",
    "        and not key.startswith(\"label:\")\n",
    "        and key[0].isupper()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullurl = data[random.choice(keys)]\n",
    "url, id_ = fullurl.split(\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = urlparse(url).geturl().replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = session.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res2.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_element = soup.find(\"dt\", {'id' : id_})\r\n",
    "base_parent = base_element.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = base_parent.find(\"dd\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(para)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}